// filepath: /home/oliver/git/nifi-extensions/doc/implement-end-to-end.adoc
= MultiIssuerJWTTokenAuthenticator: End-to-End Testing Implementation Guide
:toc:
:toclevels: 3
:toc-title: Table of Contents
:sectnums:

link:Specification.adoc[Back to Main Specification]

== Overview

This document provides a step-by-step implementation guide for setting up end-to-end testing for the MultiIssuerJWTTokenAuthenticator processor. It serves as an actionable plan to implement the testing approach described in the link:specification/end-to-end-testing.adoc[End-to-End Testing Specification].

The implementation follows a phased approach, allowing incremental deployment and verification of the testing infrastructure and test cases.

== Prerequisites

Before beginning implementation, ensure the following prerequisites are met:

* Java Development Kit (JDK) 11 or higher
* Apache Maven 3.8.0 or higher
* Node.js 16.x or higher
* Docker 24.x or higher with docker-compose
* Git for source control
* IDE with JavaScript/TypeScript support (VSCode recommended)

== Implementation Plan

=== Phase 1: Environment Setup ✅

[cols="1,3,1", options="header"]
|===
|Task |Description |Status

|1.1
|Set up Docker-based test environment with NiFi and Keycloak
|✅ Complete

|1.2
|Configure self-signed certificates for HTTPS
|✅ Complete

|1.3
|Set up Keycloak realm with test users and clients
|✅ Complete

|1.4
|Verify connectivity between containers
|✅ Complete

|1.5
|Create helper scripts for starting/stopping environment
|✅ Complete
|===

[NOTE]
====
Refer to the link:specification/end-to-end-testing.adoc#_containerized_testing_environment[Containerized Testing Environment] section in the specification for detailed requirements.
====

==== Implementation Status

Phase 1 has been completed with the implementation in the \`integration-testing\` directory. The environment provides:

1. Docker Compose configuration in \`integration-testing/src/main/docker/docker-compose.yml\` with NiFi and Keycloak containers
2. Helper scripts for environment management:
* \`run-test-container.sh\`: Builds NAR, checks certificates, starts containers
* \`stop-test-container.sh\`: Stops and removes containers
* \`copy-deployment.sh\`: Builds NAR and copies to deployment location
* \`redeploy-nifi.sh\`: Rebuilds and redeploys during development
3. Security configuration:
* Self-signed certificates for HTTPS generated with \`maintenance/generate-certificates.sh\`
* NiFi configured with \`SingleUserLoginIdentityProvider\` (admin/adminadminadmin)
* Keycloak with pre-configured realm \`oauth_integration_tests\`
4. Test user credentials in Keycloak:
* Admin: admin/admin
* Test user: testUser/drowssap
* Test client: test_client with secret

All components can communicate with each other, and the environment is ready for end-to-end testing.

For details, see the link:../integration-testing/README.adoc[Integration Testing README].

=== Phase 2: Cypress Setup

[cols="1,3,1", options="header"]
|===
|Task |Description |Status

|2.1
|Initialize Cypress project structure
|□ Open

|2.2
|Configure Cypress for cross-browser testing
|□ Open

|2.3
|Set up console error monitoring system
|□ Open

|2.4
|Create basic page objects and utilities
|□ Open

|2.5
|Implement token generation utilities
|□ Open
|===

[NOTE]
====
Refer to the link:specification/end-to-end-testing.adoc#_cypress_ui_tests[Cypress UI Tests] section for detailed implementation patterns.
====

==== Implementation Steps

1. Initialize Cypress in the new `e-2-e-cypress` module (instead of `nifi-cuioss-ui`)
2. Set up project structure according to the specification
3. Configure linting and formatting rules
4. Create base page objects for NiFi canvas and processor configuration
5. Implement console error verification system with allowed warnings list
6. Set up test fixtures directory structure
7. Create token generation utilities using Keycloak API

==== e-2-e-cypress Module Structure

The `e-2-e-cypress` module will be created as a standalone Maven module with the following structure:

[source]
----
e-2-e-cypress/
├── pom.xml                     # Maven configuration
├── package.json                # Node/Cypress dependencies
├── cypress.config.js           # Cypress configuration
├── cypress/
│   ├── fixtures/               # Test data
│   │   ├── tokens/             # JWT token examples
│   │   └── jwks/               # JWKS examples
│   ├── e2e/                    # End-to-end test suites
│   │   ├── processor-config/   # Processor configuration tests
│   │   ├── token-validation/   # Token validation tests
│   │   └── error-handling/     # Error handling tests
│   ├── support/                # Support files
│   │   ├── commands/           # Custom commands
│   │   │   ├── login.js        # Login commands
│   │   │   ├── navigation.js   # Navigation commands
│   │   │   ├── processor.js    # Processor configuration commands
│   │   │   └── validation.js   # Validation-specific commands
│   │   ├── commands.js         # Main commands file
│   │   ├── e2e.js              # e2e support file
│   │   └── console-error-tracking.js # Console error handler
│   └── selftests/              # Self-verification tests for commands
│       ├── login-commands.cy.js # Tests for login commands
│       ├── navigation-commands.cy.js # Tests for navigation commands
│       └── processor-commands.cy.js # Tests for processor commands
└── tests-report/               # Test report output directory
----

==== Cypress Custom Commands with Self-Verification

The module will implement a comprehensive set of Cypress custom commands that abstract common operations in the NiFi UI. Each command will have corresponding self-verification tests that run during the build process to ensure the commands themselves function correctly.

===== Command Categories

1. *Login Commands*
   * `cy.nifiLogin(username, password)` - Login to NiFi UI
   * `cy.keycloakLogin(username, password)` - Login to Keycloak
   * `cy.verifyLoggedIn()` - Verify successful login state

2. *Navigation Commands*
   * `cy.navigateToCanvas()` - Navigate to NiFi canvas
   * `cy.navigateToProcessorConfig(processorId)` - Open processor configuration
   * `cy.navigateToControllerServices()` - Navigate to controller services

3. *Processor Commands*
   * `cy.addProcessor(type, position)` - Add processor to canvas
   * `cy.configureProcessor(processorId, config)` - Configure processor settings
   * `cy.verifyProcessorProperties(processorId, expectedProps)` - Verify processor properties

4. *JWT Token Commands*
   * `cy.generateToken(claims)` - Generate JWT token with specific claims
   * `cy.verifyTokenValidation(tokenId)` - Verify token validation results

===== Self-Verification Tests

Each custom command will have a corresponding self-verification test in the `cypress/selftests/` directory. These tests will:

1. Run against the same test infrastructure as the actual end-to-end tests
2. Verify that the commands operate correctly in isolation
3. Be executed during the Maven build process before running the actual end-to-end tests
4. Generate detailed reports to identify any command failures early

[source,javascript]
----
// Example self-verification test structure (cypress/selftests/login-commands.cy.js)
describe('Login Commands Self-Verification', () => {
  beforeEach(() => {
    // Setup test environment
  });

  it('should login to NiFi UI successfully', () => {
    cy.nifiLogin('admin', 'adminadminadmin');
    cy.verifyLoggedIn();
  });

  it('should handle failed login attempts', () => {
    cy.nifiLogin('wrong', 'credentials')
      .should('not.succeed');
    cy.get('.login-error').should('be.visible');
  });
});
----

===== Maven Integration for Self-Tests

The `pom.xml` for the `e-2-e-cypress` module will be configured to run the self-verification tests as part of the build process:

1. Self-tests will run before the actual end-to-end tests
2. Self-tests will use a dedicated Cypress configuration
3. Failed self-tests will fail the build to ensure command integrity
4. Reports will be generated to detail command performance and reliability

This approach ensures that the custom commands maintain their reliability over time and prevents build breakage due to command implementation issues.

==== JavaScript Code Standards and Structure

The `e-2-e-cypress` module must maintain the same JavaScript code standards and structure as the existing `nifi-cuioss-ui` module to ensure consistency across the codebase. This includes:

1. *Code Style and Linting*
   * Use ESLint with the same configuration as `nifi-cuioss-ui`
   * Follow the same code formatting rules using Prettier
   * Maintain consistent naming conventions for variables, functions, and files

2. *Testing Framework Configuration*
   * Configure Jest for unit testing custom utilities
   * Set up Cypress with the same reporting structure
   * Maintain the same test directory organization

3. *Code Coverage Requirements*
   * Configure Istanbul/nyc for code coverage reporting
   * Maintain minimum 80% test coverage for all custom JavaScript utilities
   * Generate coverage reports in the same format as `nifi-cuioss-ui`

4. *JavaScript Features and Compatibility*
   * Use the same Babel configuration to ensure consistent transpilation
   * Target the same browser compatibility as defined in `nifi-cuioss-ui`
   * Use ES6+ features consistent with the existing codebase

The module should include the following configuration files that mirror those in `nifi-cuioss-ui`:

[source]
----
e-2-e-cypress/
├── .eslintrc.js                # ESLint configuration matching nifi-cuioss-ui
├── .prettierrc                 # Prettier configuration
├── babel.config.js             # Babel configuration
├── jest.config.js              # Jest configuration for unit tests
├── cypress.config.js           # Cypress configuration
└── package.json                # NPM dependencies and scripts
----

===== Integration with Existing Code Standards

To ensure integration with existing code standards:

1. Copy the relevant configuration files from `nifi-cuioss-ui` as a starting point
2. Update paths and module-specific settings as needed
3. Include the same NPM scripts for linting, testing, and coverage reporting
4. Configure the same pre-commit hooks for code quality checks

===== Code Coverage Configuration

The coverage configuration should include:

[source,javascript]
----
// Example jest.config.js for unit tests
module.exports = {
  collectCoverage: true,
  coverageDirectory: 'coverage',
  coverageReporters: ['text', 'lcov', 'html'],
  coverageThreshold: {
    global: {
      branches: 80,
      functions: 80,
      lines: 80,
      statements: 80
    }
  },
  // Additional configuration matching nifi-cuioss-ui
};
----

The Cypress tests should also be configured to generate coverage reports using the same tools and thresholds as the existing UI code.

This approach ensures that all JavaScript code, including the end-to-end tests and custom utilities, maintains the same quality standards and consistency across the project.

=== Phase 3: Basic Test Implementation

[cols="1,3,1", options="header"]
|===
|Task |Description |Status

|3.1
|Implement login and navigation helpers
|□ Open

|3.2
|Create processor configuration tests
|□ Open

|3.3
|Implement token verification tests
|□ Open

|3.4
|Create JWKS validation tests
|□ Open

|3.5
|Implement error handling tests
|□ Open
|===

[NOTE]
====
Refer to the link:specification/end-to-end-testing.adoc#_end_to_end_test_scenarios[End-to-End Test Scenarios] section for the required test cases.
====

==== Implementation Steps

1. Implement Cypress custom commands for login and navigation
2. Create basic processor configuration tests
3. Implement token verification tests for valid and invalid tokens
4. Create JWKS validation tests for server, file, and in-memory types
5. Implement error scenario tests for configuration and validation

=== Phase 4: CI/CD Integration

[cols="1,3,1", options="header"]
|===
|Task |Description |Status

|4.1
|Configure Maven integration
|□ Open

|4.2
|Set up GitHub Actions workflow
|□ Open

|4.3
|Configure test reporting
|□ Open

|4.4
|Implement console error analysis in CI
|□ Open

|4.5
|Create documentation for CI process
|□ Open
|===

[NOTE]
====
Refer to the link:specification/end-to-end-testing.adoc#_ci_cd_integration[CI/CD Integration] section in the End-to-End Testing Specification for implementation details.
====

==== Implementation Steps

1. Configure Maven plugins for test execution
2. Create GitHub Actions workflow file
3. Set up test reporting and artifact collection
4. Implement console error analysis in the CI pipeline
5. Document the CI/CD process for team reference

=== Phase 5: Advanced Test Implementation

[cols="1,3,1", options="header"]
|===
|Task |Description |Status

|5.1
|Implement metrics and statistics tests
|□ Open

|5.2
|Create internationalization tests
|□ Open

|5.3
|Implement cross-browser tests
|□ Open

|5.4
|Create accessibility tests
|□ Open

|5.5
|Implement visual testing
|□ Open
|===

[NOTE]
====
Refer to the link:specification/end-to-end-testing.adoc#_accessibility_testing_flow[Accessibility Testing Flow] and link:specification/end-to-end-testing.adoc#_visual_testing[Visual Testing] sections for implementation details.
====

==== Implementation Steps

1. Create metrics display and verification tests
2. Implement internationalization tests with language switching
3. Extend tests with browser-specific handling
4. Add accessibility testing with axe-core
5. Implement visual comparison tests with screenshots

== Test Code Structure

Refer to the link:specification/end-to-end-testing.adoc#_test_code_structure[Test Code Structure] section in the End-to-End Testing Specification for detailed information about the test code organization.

== Console Error Verification Implementation

Follow these steps to implement the console error verification system:

1. Create the allowlist file:

[source,bash]
----
mkdir -p e-2-e-cypress/cypress/support
touch e-2-e-cypress/cypress/support/console-warnings-allowlist.js
----

2. Implement the allowlist with initial known warnings:

[source,javascript]
----
// Add only warnings that cannot be fixed
module.exports = [
  'Warning: validateDOMNesting(...): <div> cannot appear as a descendant of <p>.',
  'DevTools failed to load source map',
  'Content Security Policy violation for inline script'
];
----

3. Implement console error tracking in Cypress:

[source,bash]
----
touch e-2-e-cypress/cypress/support/console-error-tracking.js
----

4. Add the console error tracking implementation as specified in the link:specification/end-to-end-testing.adoc#_console_error_verification[Console Error Verification] section.

== Maven Integration

To integrate with Maven, follow these steps:

1. Configure the `frontend-maven-plugin` in the `e-2-e-cypress/pom.xml` file
2. Add the necessary NPM scripts to `package.json`
3. Configure the Maven Failsafe plugin for integration testing
4. Set up system properties for test environment URLs

=== Maven Configuration for Self-Verification Tests

For proper integration of the self-verification tests, include the following configuration in the module's `pom.xml`:

[source,xml]
----
<plugin>
  <groupId>com.github.eirslett</groupId>
  <artifactId>frontend-maven-plugin</artifactId>
  <executions>
    <!-- Standard npm and node setup -->
    <execution>
      <id>install-node-and-npm</id>
      <!-- ... -->
    </execution>
    <!-- Run self-verification tests first -->
    <execution>
      <id>cypress-selftests</id>
      <goals>
        <goal>npm</goal>
      </goals>
      <phase>pre-integration-test</phase>
      <configuration>
        <arguments>run cypress:selftests</arguments>
        <environmentVariables>
          <CYPRESS_BASE_URL>https://localhost:8443/nifi</CYPRESS_BASE_URL>
          <CYPRESS_KEYCLOAK_URL>https://localhost:8443/auth</CYPRESS_KEYCLOAK_URL>
        </environmentVariables>
        <failOnError>true</failOnError>
      </configuration>
    </execution>
    <!-- Run actual E2E tests only if self-tests pass -->
    <execution>
      <id>cypress-e2e</id>
      <goals>
        <goal>npm</goal>
      </goals>
      <phase>integration-test</phase>
      <configuration>
        <arguments>run cypress:run</arguments>
        <!-- ... -->
      </configuration>
    </execution>
  </executions>
</plugin>
----

The corresponding NPM scripts in `package.json`:

[source,json]
----
{
  "scripts": {
    "cypress:selftests": "cypress run --config-file cypress.selftests.config.js",
    "cypress:run": "cypress run",
    "cypress:open": "cypress open"
  }
}
----

With a special self-tests configuration file (`cypress.selftests.config.js`):

[source,javascript]
----
const { defineConfig } = require('cypress');

module.exports = defineConfig({
  e2e: {
    specPattern: 'cypress/selftests/**/*.cy.js',
    supportFile: 'cypress/support/selftests.js',
    // Set shorter timeouts for self-tests as they should be fast
    defaultCommandTimeout: 5000,
    video: false,
    // Generate a separate report for self-tests
    reporter: 'junit',
    reporterOptions: {
      mochaFile: 'tests-report/selftests-[hash].xml',
      toConsole: true
    }
  }
});
----

Refer to the link:specification/end-to-end-testing.adoc#_maven_integration[Maven Integration] section for additional configuration examples.

== CI/CD Integration

For CI/CD integration with GitHub Actions:

1. Create a workflow file at \`.github/workflows/e2e-tests.yml\`
2. Configure the workflow to set up Node.js and Java
3. Add steps to start the test environment
4. Configure Cypress test execution
5. Add steps for console error analysis
6. Configure artifact upload for test results

Refer to the link:specification/end-to-end-testing.adoc#_ci_cd_integration[CI/CD Integration] section for workflow configuration examples.

== Monitoring and Maintenance

After implementation, establish a maintenance process:

1. Schedule regular reviews of the allowed warnings list
2. Monitor test stability and flakiness
3. Update tests when the UI changes
4. Regularly update test data and fixtures
5. Review console error analysis reports for trends

Refer to the link:specification/end-to-end-testing.adoc#_test_maintenance[Test Maintenance] section for best practices.

== References

* link:specification/end-to-end-testing.adoc[End-to-End Testing Specification]
* link:specification/configuration-ui.adoc[UI Configuration Specification]
* link:specification/token-validation.adoc[Token Validation Specification]
* link:Requirements.adoc#NIFI-AUTH-16[Testing Requirements]
* link:library/cui-test-keycloak-integration/README.adoc[Keycloak Integration Testing]
* link:integration-testing/README.adoc[Integration Testing Environment]

==== JavaScript Code Standards and Structure

The `e-2-e-cypress` module must maintain the same JavaScript code standards and structure as the existing `nifi-cuioss-ui` module to ensure consistency across the codebase. This includes:

1. *Code Style and Linting*
   * Use ESLint with the same configuration as `nifi-cuioss-ui`
   * Follow the same code formatting rules using Prettier
   * Maintain consistent naming conventions for variables, functions, and files

2. *Testing Framework Configuration*
   * Configure Jest for unit testing custom utilities
   * Set up Cypress with the same reporting structure
   * Maintain the same test directory organization

3. *Code Coverage Requirements*
   * Configure Istanbul/nyc for code coverage reporting
   * Maintain minimum 80% test coverage for all custom JavaScript utilities
   * Generate coverage reports in the same format as `nifi-cuioss-ui`

4. *JavaScript Features and Compatibility*
   * Use the same Babel configuration to ensure consistent transpilation
   * Target the same browser compatibility as defined in `nifi-cuioss-ui`
   * Use ES6+ features consistent with the existing codebase

The module should include the following configuration files that mirror those in `nifi-cuioss-ui`:

[source]
----
e-2-e-cypress/
├── .eslintrc.js                # ESLint configuration matching nifi-cuioss-ui
├── .prettierrc                 # Prettier configuration
├── babel.config.js             # Babel configuration
├── jest.config.js              # Jest configuration for unit tests
├── cypress.config.js           # Cypress configuration
└── package.json                # NPM dependencies and scripts
----

===== Integration with Existing Code Standards

To ensure integration with existing code standards:

1. Copy the relevant configuration files from `nifi-cuioss-ui` as a starting point
2. Update paths and module-specific settings as needed
3. Include the same NPM scripts for linting, testing, and coverage reporting
4. Configure the same pre-commit hooks for code quality checks

===== Code Coverage Configuration

The coverage configuration should include:

[source,javascript]
----
// Example jest.config.js for unit tests
module.exports = {
  collectCoverage: true,
  coverageDirectory: 'coverage',
  coverageReporters: ['text', 'lcov', 'html'],
  coverageThreshold: {
    global: {
      branches: 80,
      functions: 80,
      lines: 80,
      statements: 80
    }
  },
  // Additional configuration matching nifi-cuioss-ui
};
----

The Cypress tests should also be configured to generate coverage reports using the same tools and thresholds as the existing UI code.

This approach ensures that all JavaScript code, including the end-to-end tests and custom utilities, maintains the same quality standards and consistency across the project.
